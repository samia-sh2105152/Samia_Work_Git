{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97285689-8e0f-4594-a74d-8275605b77ad",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align: center;font-weight: bold;\">Design and Implementation of a CNN-Based OCR System for License Plate Recognition in Qatar</h1>\n",
    "<h4 style=\"text-align: center;\">Group #2</h3>\n",
    "<table>\n",
    "  <tr>\n",
    "    <th>Student Name</th>\n",
    "    <th>QU ID</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Aisha Al-Shahwani</td>\n",
    "    <td>202005623</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Abir Sidilemine</td>\n",
    "    <td>202104894</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Samia Hasan</td>\n",
    "    <td>202105152</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Shaima Nasser</td>\n",
    "    <td>202004047</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Zobia Zia</td>\n",
    "    <td>202108274</td>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7bfa6c9-7e95-437f-9787-f0c4ae8c0239",
   "metadata": {},
   "source": [
    "<b>Step 1: Set Up the Environment</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69fee683-0cbf-4f58-bc09-682a2908b09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone YOLOv5 Repository: Open your terminal and run\n",
    "#git clone https://github.com/ultralytics/yolov5\n",
    "\n",
    "# Navigate to YOLOv5 Directory:\n",
    "#cd /Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/Models  # Adjust path if necessary\n",
    "\n",
    "# Install Dependencies:\n",
    "#pip install -r requirements.txt\n",
    "\n",
    "# Download YOLOv5 Weights Manually: \n",
    "#curl -L -o yolov5m.pt https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5m.pt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1651397-c6bd-48a0-aa24-f297b9093d38",
   "metadata": {},
   "source": [
    "<b>Step 2: Load the YOLOv5 Model</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c59802b0-e8d1-43e1-bf36-8a0b29ba76c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5 ðŸš€ v7.0-383-g1435a8ee Python-3.12.4 torch-2.5.1 CPU\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5m summary: 290 layers, 21172173 parameters, 0 gradients, 48.9 GFLOPs\n",
      "Adding AutoShape... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLOv5 model loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Load YOLOv5 model with the path to the repository and weights file\n",
    "model = torch.hub.load(\n",
    "    '/Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/yolov5', \n",
    "    'custom', \n",
    "    path='/Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/yolov5m.pt', \n",
    "    source='local', \n",
    "    force_reload=True\n",
    ")\n",
    "\n",
    "print(\"YOLOv5 model loaded successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cae8068-777b-4924-b873-b432b75103da",
   "metadata": {},
   "source": [
    "<b>Step 3: Load and Display Images</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d250609-4fac-4ed3-9736-f6d70b86f946",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 43 images in the directory.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import math\n",
    "import re\n",
    "\n",
    "def natural_sort_key(s):\n",
    "    # Extracts the numerical part from filenames for natural sorting\n",
    "    return [int(text) if text.isdigit() else text.lower() for text in re.split(r'(\\d+)', s)]\n",
    "\n",
    "def display_jpeg_images_in_grid(folder_path, images_per_row=4):\n",
    "    # Collect only .jpeg images and sort numerically based on extracted numbers\n",
    "    image_paths = [os.path.join(folder_path, img) \n",
    "                   for img in sorted(os.listdir(folder_path), key=natural_sort_key) \n",
    "                   if img.endswith('.jpeg') or img.endswith('.jpg')]\n",
    "    \n",
    "    print(f\"Found {len(image_paths)} images in the directory.\")\n",
    "\n",
    "    if len(image_paths) == 0:\n",
    "        print(\"No .jpeg images found in the specified directory.\")\n",
    "        return\n",
    "\n",
    "    # Load images without resizing\n",
    "    images = []\n",
    "    for path in image_paths:\n",
    "        img = cv2.imread(path)\n",
    "        if img is not None:\n",
    "            images.append(img)\n",
    "        else:\n",
    "            print(f\"Could not load image at {path}\")\n",
    "\n",
    "    # Calculate the number of rows needed based on images_per_row\n",
    "    num_images = len(images)\n",
    "    num_rows = math.ceil(num_images / images_per_row)\n",
    "\n",
    "    # Display images in a grid format\n",
    "    fig, axes = plt.subplots(num_rows, images_per_row, figsize=(20, 5 * num_rows))\n",
    "    axes = axes.flatten()  # Flatten in case of multiple rows\n",
    "\n",
    "    for i, img in enumerate(images):\n",
    "        axes[i].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "        axes[i].axis('off')\n",
    "        axes[i].set_title(f\"Image {i + 1}\")\n",
    "\n",
    "    # Hide any extra subplots if there are fewer images than grid cells\n",
    "    for j in range(i + 1, len(axes)):\n",
    "        axes[j].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "display_jpeg_images_in_grid('/Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/Car Plates');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6036ebc-57f6-442f-a995-3253e7eb3efd",
   "metadata": {},
   "source": [
    "<b>Step 4.a: Detect and Annotate Objects in Images Using YOLOv5</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "115977b3-5300-4f6e-a81e-34c9279b0d38",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5 ðŸš€ v7.0-383-g1435a8ee Python-3.12.4 torch-2.5.1 CPU\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5m summary: 290 layers, 21172173 parameters, 0 gradients, 48.9 GFLOPs\n",
      "Adding AutoShape... \n",
      "/Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/yolov5/models/common.py:892: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully.\n",
      "Processing /Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/Car Plates/1.jpeg...\n",
      "Saved detected image as /Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/Detected Images/detected_1.jpg\n",
      "Processing /Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/Car Plates/10.jpeg...\n",
      "Saved detected image as /Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/Detected Images/detected_10.jpg\n",
      "Processing /Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/Car Plates/11.jpeg...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/yolov5/models/common.py:892: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n",
      "/Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/yolov5/models/common.py:892: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved detected image as /Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/Detected Images/detected_11.jpg\n",
      "Processing /Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/Car Plates/12.jpeg...\n",
      "Saved detected image as /Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/Detected Images/detected_12.jpg\n",
      "Processing /Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/Car Plates/13.jpeg...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/yolov5/models/common.py:892: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n",
      "/Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/yolov5/models/common.py:892: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved detected image as /Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/Detected Images/detected_13.jpg\n",
      "Processing /Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/Car Plates/14.jpeg...\n",
      "Saved detected image as /Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/Detected Images/detected_14.jpg\n",
      "Processing /Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/Car Plates/15.jpeg...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/yolov5/models/common.py:892: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n",
      "/Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/yolov5/models/common.py:892: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved detected image as /Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/Detected Images/detected_15.jpg\n",
      "Processing /Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/Car Plates/16.jpeg...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/yolov5/models/common.py:892: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved detected image as /Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/Detected Images/detected_16.jpg\n",
      "Processing /Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/Car Plates/17.jpeg...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/yolov5/models/common.py:892: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved detected image as /Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/Detected Images/detected_17.jpg\n",
      "Processing /Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/Car Plates/18.jpeg...\n",
      "Saved detected image as /Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/Detected Images/detected_18.jpg\n",
      "Processing /Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/Car Plates/19.jpeg...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/yolov5/models/common.py:892: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n",
      "/Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/yolov5/models/common.py:892: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved detected image as /Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/Detected Images/detected_19.jpg\n",
      "Processing /Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/Car Plates/2.jpeg...\n",
      "Saved detected image as /Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/Detected Images/detected_2.jpg\n",
      "Processing /Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/Car Plates/20.jpeg...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/yolov5/models/common.py:892: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n",
      "/Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/yolov5/models/common.py:892: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved detected image as /Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/Detected Images/detected_20.jpg\n",
      "Processing /Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/Car Plates/21.jpeg...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/yolov5/models/common.py:892: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved detected image as /Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/Detected Images/detected_21.jpg\n",
      "Processing /Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/Car Plates/22.jpeg...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/yolov5/models/common.py:892: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved detected image as /Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/Detected Images/detected_22.jpg\n",
      "Processing /Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/Car Plates/23.jpeg...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/yolov5/models/common.py:892: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved detected image as /Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/Detected Images/detected_23.jpg\n",
      "Processing /Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/Car Plates/24.jpeg...\n",
      "Saved detected image as /Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/Detected Images/detected_24.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/yolov5/models/common.py:892: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/Car Plates/25.jpeg...\n",
      "Saved detected image as /Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/Detected Images/detected_25.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/yolov5/models/common.py:892: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/Car Plates/26.jpeg...\n",
      "Saved detected image as /Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/Detected Images/detected_26.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/yolov5/models/common.py:892: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/Car Plates/27.jpeg...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/yolov5/models/common.py:892: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved detected image as /Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/Detected Images/detected_27.jpg\n",
      "Processing /Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/Car Plates/28.jpeg...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/yolov5/models/common.py:892: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved detected image as /Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/Detected Images/detected_28.jpg\n",
      "Processing /Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/Car Plates/29.jpeg...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/yolov5/models/common.py:892: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n",
      "/Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/yolov5/models/common.py:892: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved detected image as /Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/Detected Images/detected_29.jpg\n",
      "Processing /Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/Car Plates/3.jpeg...\n",
      "Saved detected image as /Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/Detected Images/detected_3.jpg\n",
      "Processing /Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/Car Plates/30.jpeg...\n",
      "Saved detected image as /Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/Detected Images/detected_30.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/yolov5/models/common.py:892: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/Car Plates/31.jpeg...\n",
      "Saved detected image as /Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/Detected Images/detected_31.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/yolov5/models/common.py:892: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/Car Plates/32.jpeg...\n",
      "Saved detected image as /Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/Detected Images/detected_32.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/yolov5/models/common.py:892: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/Car Plates/33.jpeg...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/yolov5/models/common.py:892: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved detected image as /Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/Detected Images/detected_33.jpg\n",
      "Processing /Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/Car Plates/34.jpeg...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/yolov5/models/common.py:892: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved detected image as /Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/Detected Images/detected_34.jpg\n",
      "Processing /Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/Car Plates/35.jpeg...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/yolov5/models/common.py:892: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved detected image as /Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/Detected Images/detected_35.jpg\n",
      "Processing /Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/Car Plates/36.jpeg...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/yolov5/models/common.py:892: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved detected image as /Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/Detected Images/detected_36.jpg\n",
      "Processing /Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/Car Plates/37.jpeg...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/yolov5/models/common.py:892: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved detected image as /Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/Detected Images/detected_37.jpg\n",
      "Processing /Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/Car Plates/38.jpeg...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/yolov5/models/common.py:892: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved detected image as /Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/Detected Images/detected_38.jpg\n",
      "Processing /Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/Car Plates/39.jpeg...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/yolov5/models/common.py:892: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved detected image as /Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/Detected Images/detected_39.jpg\n",
      "Processing /Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/Car Plates/4.jpeg...\n",
      "Saved detected image as /Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/Detected Images/detected_4.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/yolov5/models/common.py:892: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/Car Plates/40.jpeg...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/yolov5/models/common.py:892: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved detected image as /Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/Detected Images/detected_40.jpg\n",
      "Processing /Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/Car Plates/41.jpeg...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/yolov5/models/common.py:892: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved detected image as /Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/Detected Images/detected_41.jpg\n",
      "Processing /Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/Car Plates/42.jpeg...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/yolov5/models/common.py:892: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n",
      "/Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/yolov5/models/common.py:892: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved detected image as /Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/Detected Images/detected_42.jpg\n",
      "Processing /Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/Car Plates/43.jpg...\n",
      "Saved detected image as /Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/Detected Images/detected_43.jpg\n",
      "Processing /Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/Car Plates/5.jpeg...\n",
      "Saved detected image as /Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/Detected Images/detected_5.jpg\n",
      "Processing /Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/Car Plates/6.jpeg...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/yolov5/models/common.py:892: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n",
      "/Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/yolov5/models/common.py:892: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved detected image as /Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/Detected Images/detected_6.jpg\n",
      "Processing /Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/Car Plates/7.jpeg...\n",
      "Saved detected image as /Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/Detected Images/detected_7.jpg\n",
      "Processing /Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/Car Plates/8.jpeg...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/yolov5/models/common.py:892: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n",
      "/Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/yolov5/models/common.py:892: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved detected image as /Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/Detected Images/detected_8.jpg\n",
      "Processing /Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/Car Plates/9.jpeg...\n",
      "Saved detected image as /Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/Detected Images/detected_9.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/yolov5/models/common.py:892: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import cv2\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Path to the YOLOv5 model directory and weights file\n",
    "yolo_dir = \"/Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/yolov5\"\n",
    "model_path = \"/Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/yolov5m.pt\"\n",
    "\n",
    "# Load YOLOv5 model\n",
    "try:\n",
    "    model = torch.hub.load(yolo_dir, 'custom', path=model_path, source='local')\n",
    "    print(\"Model loaded successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading YOLOv5 model: {e}\")\n",
    "    exit()\n",
    "\n",
    "# Detect objects in images using YOLOv5 and save the results with bounding boxes.\n",
    "def detect_and_save_images(input_folder, output_folder, conf_threshold=0.3):\n",
    "    # Create the output folder if it doesn't exist\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # Get list of image files in the input folder\n",
    "    image_files = sorted(\n",
    "        [Path(input_folder) / img for img in os.listdir(input_folder) if img.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "    )\n",
    "\n",
    "    if not image_files:\n",
    "        print(\"No images found in the input folder.\")\n",
    "        return\n",
    "\n",
    "    for image_file in image_files:\n",
    "        # Load image\n",
    "        image = cv2.imread(str(image_file))\n",
    "        if image is None:\n",
    "            print(f\"Error: Could not load {image_file}\")\n",
    "            continue\n",
    "\n",
    "        print(f\"Processing {image_file}...\")\n",
    "\n",
    "        # Run inference\n",
    "        results = model(image)\n",
    "\n",
    "        # Extract detections\n",
    "        try:\n",
    "            detections = results.xyxy[0].cpu().numpy()  # Bounding boxes\n",
    "        except Exception as e:\n",
    "            print(f\"Error extracting detections from {image_file}: {e}\")\n",
    "            continue\n",
    "\n",
    "        if detections.size == 0:\n",
    "            print(f\"No detections for {image_file}\")\n",
    "            continue\n",
    "\n",
    "        # Draw bounding boxes on the image\n",
    "        for *box, conf, cls in detections:\n",
    "            if conf >= conf_threshold:\n",
    "                x_min, y_min, x_max, y_max = map(int, box)\n",
    "                cv2.rectangle(image, (x_min, y_min), (x_max, y_max), (0, 255, 0), 2)\n",
    "                # Optionally, add the confidence and class labels\n",
    "                label = f\"{model.names[int(cls)]} {conf:.2f}\"\n",
    "                cv2.putText(image, label, (x_min, y_min - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)\n",
    "\n",
    "        # Save the processed image with bounding boxes\n",
    "        output_image_path = Path(output_folder) / f\"detected_{image_file.stem}.jpg\"\n",
    "        cv2.imwrite(str(output_image_path), image)\n",
    "        print(f\"Saved detected image as {output_image_path}\")\n",
    "\n",
    "# Folder containing the car plate images\n",
    "input_folder = \"/Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/Car Plates\"\n",
    "# Folder to save the detected images\n",
    "output_folder = \"/Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/Detected Images\"\n",
    "\n",
    "# Run the detection\n",
    "detect_and_save_images(input_folder, output_folder, conf_threshold=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a344825b-172f-48ec-ad32-b04d407bad26",
   "metadata": {},
   "source": [
    "<b>Step 4.b: Display the Detected Objects</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cdfcd466-e3fa-4571-bc89-cada2abf698e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 43 images in the directory.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import math\n",
    "import re\n",
    "\n",
    "def natural_sort_key(s):\n",
    "    # Extracts the numerical part from filenames for natural sorting\n",
    "    return [int(text) if text.isdigit() else text.lower() for text in re.split(r'(\\d+)', s)]\n",
    "\n",
    "def display_jpeg_images_in_grid(folder_path, images_per_row=4):\n",
    "    # Collect only .jpeg and .jpg images and sort numerically based on extracted numbers\n",
    "    image_paths = [os.path.join(folder_path, img) \n",
    "                   for img in sorted(os.listdir(folder_path), key=natural_sort_key) \n",
    "                   if img.endswith('.jpeg') or img.endswith('.jpg')]\n",
    "    \n",
    "    print(f\"Found {len(image_paths)} images in the directory.\")  # Debugging line\n",
    "\n",
    "    if len(image_paths) == 0:\n",
    "        print(\"No .jpeg or .jpg images found in the specified directory.\")\n",
    "        return\n",
    "\n",
    "    # Load images without resizing\n",
    "    images = []\n",
    "    for path in image_paths:\n",
    "        img = cv2.imread(path)\n",
    "        if img is not None:\n",
    "            images.append(img)\n",
    "        else:\n",
    "            print(f\"Could not load image at {path}\")\n",
    "\n",
    "    # Calculate the number of rows needed based on images_per_row\n",
    "    num_images = len(images)\n",
    "    num_rows = math.ceil(num_images / images_per_row)\n",
    "\n",
    "    # Display images in a grid format\n",
    "    fig, axes = plt.subplots(num_rows, images_per_row, figsize=(20, 5 * num_rows))\n",
    "    axes = axes.flatten()  # Flatten in case of multiple rows\n",
    "\n",
    "    for i, img in enumerate(images):\n",
    "        axes[i].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "        axes[i].axis('off')\n",
    "        axes[i].set_title(f\"Image {i + 1}\")\n",
    "\n",
    "    # Hide any extra subplots if there are fewer images than grid cells\n",
    "    for j in range(i + 1, len(axes)):\n",
    "        axes[j].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "display_jpeg_images_in_grid('/Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/Detected Images')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c9fc0e-b21b-4af3-88d3-057d69457d84",
   "metadata": {},
   "source": [
    "<b>Step 4.c: Crop the Car Images</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "355f5765-ecf6-4319-9b13-f3009b72406e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 10.jpeg...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/yolov5/models/common.py:892: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cropped image to /Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/Cropped Plates/cropped_10.jpeg\n",
      "Processing 26.jpeg...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/yolov5/models/common.py:892: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cropped image to /Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/Cropped Plates/cropped_26.jpeg\n",
      "Processing 30.jpeg...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/yolov5/models/common.py:892: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cropped image to /Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/Cropped Plates/cropped_30.jpeg\n",
      "Processing 31.jpeg...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/yolov5/models/common.py:892: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cropped image to /Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/Cropped Plates/cropped_31.jpeg\n",
      "Processing 27.jpeg...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/yolov5/models/common.py:892: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n",
      "/Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/yolov5/models/common.py:892: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cropped image to /Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/Cropped Plates/cropped_27.jpeg\n",
      "Processing 1.jpeg...\n",
      "Saved cropped image to /Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/Cropped Plates/cropped_1.jpeg\n",
      "Processing 11.jpeg...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/yolov5/models/common.py:892: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cropped image to /Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/Cropped Plates/cropped_11.jpeg\n",
      "Processing 20.jpeg...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/yolov5/models/common.py:892: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cropped image to /Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/Cropped Plates/cropped_20.jpeg\n",
      "Processing 36.jpeg...\n",
      "Saved cropped image to /Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/Cropped Plates/cropped_36.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/yolov5/models/common.py:892: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 41.jpeg...\n",
      "Saved cropped image to /Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/Cropped Plates/cropped_41.jpeg\n",
      "Processing 16.jpeg...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/yolov5/models/common.py:892: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n",
      "/Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/yolov5/models/common.py:892: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cropped image to /Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/Cropped Plates/cropped_16.jpeg\n",
      "Processing 6.jpeg...\n",
      "Saved cropped image to /Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/Cropped Plates/cropped_6.jpeg\n",
      "Processing 7.jpeg...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/yolov5/models/common.py:892: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n",
      "/Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/yolov5/models/common.py:892: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cropped image to /Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/Cropped Plates/cropped_7.jpeg\n",
      "Processing 17.jpeg...\n",
      "Saved cropped image to /Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/Cropped Plates/cropped_17.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/yolov5/models/common.py:892: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n",
      "/Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/yolov5/models/common.py:892: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 40.jpeg...\n",
      "Saved cropped image to /Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/Cropped Plates/cropped_40.jpeg\n",
      "Processing 37.jpeg...\n",
      "Saved cropped image to /Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/Cropped Plates/cropped_37.jpeg\n",
      "Processing 21.jpeg...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/yolov5/models/common.py:892: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n",
      "/Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/yolov5/models/common.py:892: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cropped image to /Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/Cropped Plates/cropped_21.jpeg\n",
      "Processing 34.jpeg...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/yolov5/models/common.py:892: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n",
      "/Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/yolov5/models/common.py:892: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cropped image to /Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/Cropped Plates/cropped_34.jpeg\n",
      "Processing 8.jpeg...\n",
      "Saved cropped image to /Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/Cropped Plates/cropped_8.jpeg\n",
      "Processing 22.jpeg...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/yolov5/models/common.py:892: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n",
      "/Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/yolov5/models/common.py:892: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cropped image to /Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/Cropped Plates/cropped_22.jpeg\n",
      "Processing 18.jpeg...\n",
      "Saved cropped image to /Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/Cropped Plates/cropped_18.jpeg\n",
      "Processing 38.jpeg...\n",
      "Saved cropped image to /Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/Cropped Plates/cropped_38.jpeg\n",
      "Processing 4.jpeg...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/yolov5/models/common.py:892: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n",
      "/Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/yolov5/models/common.py:892: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cropped image to /Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/Cropped Plates/cropped_4.jpeg\n",
      "Processing 14.jpeg...\n",
      "Saved cropped image to /Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/Cropped Plates/cropped_14.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/yolov5/models/common.py:892: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 42.jpeg...\n",
      "Saved cropped image to /Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/Cropped Plates/cropped_42.jpeg\n",
      "Processing 15.jpeg...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/yolov5/models/common.py:892: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n",
      "/Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/yolov5/models/common.py:892: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cropped image to /Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/Cropped Plates/cropped_15.jpeg\n",
      "Processing 5.jpeg...\n",
      "Saved cropped image to /Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/Cropped Plates/cropped_5.jpeg\n",
      "Processing 39.jpeg...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/yolov5/models/common.py:892: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n",
      "/Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/yolov5/models/common.py:892: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cropped image to /Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/Cropped Plates/cropped_39.jpeg\n",
      "Processing 19.jpeg...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/yolov5/models/common.py:892: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cropped image to /Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/Cropped Plates/cropped_19.jpeg\n",
      "Processing 23.jpeg...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/yolov5/models/common.py:892: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cropped image to /Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/Cropped Plates/cropped_23.jpeg\n",
      "Processing 9.jpeg...\n",
      "Saved cropped image to /Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/Cropped Plates/cropped_9.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/yolov5/models/common.py:892: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 35.jpeg...\n",
      "Saved cropped image to /Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/Cropped Plates/cropped_35.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/yolov5/models/common.py:892: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 2.jpeg...\n",
      "Saved cropped image to /Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/Cropped Plates/cropped_2.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/yolov5/models/common.py:892: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 28.jpeg...\n",
      "Saved cropped image to /Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/Cropped Plates/cropped_28.jpeg\n",
      "Processing 12.jpeg...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/yolov5/models/common.py:892: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n",
      "/Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/yolov5/models/common.py:892: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cropped image to /Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/Cropped Plates/cropped_12.jpeg\n",
      "Processing 43.jpg...\n",
      "Saved cropped image to /Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/Cropped Plates/cropped_43.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/yolov5/models/common.py:892: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 32.jpeg...\n",
      "Saved cropped image to /Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/Cropped Plates/cropped_32.jpeg\n",
      "Processing 24.jpeg...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/yolov5/models/common.py:892: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n",
      "/Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/yolov5/models/common.py:892: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cropped image to /Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/Cropped Plates/cropped_24.jpeg\n",
      "Processing 25.jpeg...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/yolov5/models/common.py:892: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cropped image to /Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/Cropped Plates/cropped_25.jpeg\n",
      "Processing 33.jpeg...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/yolov5/models/common.py:892: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n",
      "/Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/yolov5/models/common.py:892: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cropped image to /Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/Cropped Plates/cropped_33.jpeg\n",
      "Processing 13.jpeg...\n",
      "Saved cropped image to /Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/Cropped Plates/cropped_13.jpeg\n",
      "Processing 29.jpeg...\n",
      "Saved cropped image to /Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/Cropped Plates/cropped_29.jpeg\n",
      "Processing 3.jpeg...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/yolov5/models/common.py:892: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n",
      "/Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/yolov5/models/common.py:892: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cropped image to /Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/Cropped Plates/cropped_3.jpeg\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "# Path to the YOLOv5 model directory and weights file\n",
    "yolo_dir = \"/Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/yolov5\"\n",
    "model_path = \"/Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/yolov5m.pt\"\n",
    "\n",
    "# Crops the largest bounding box from the image based on area.\n",
    "def crop_largest_box(image, detections):\n",
    "    max_area = 0\n",
    "    best_box = None\n",
    "\n",
    "    # Iterate through detected boxes\n",
    "    for detection in detections:\n",
    "        xmin, ymin, xmax, ymax, confidence, cls = detection\n",
    "        width = xmax - xmin\n",
    "        height = ymax - ymin\n",
    "        area = width * height\n",
    "\n",
    "        # Update if this is the largest box found\n",
    "        if area > max_area:\n",
    "            max_area = area\n",
    "            best_box = (int(xmin), int(ymin), int(xmax), int(ymax))\n",
    "\n",
    "    # Crop the largest bounding box if found\n",
    "    if best_box:\n",
    "        xmin, ymin, xmax, ymax = best_box\n",
    "        cropped_image = image[ymin:ymax, xmin:xmax]\n",
    "        return cropped_image, best_box\n",
    "    else:\n",
    "        return None, None\n",
    "\n",
    "# Processes images in the input folder, crops the largest detected bounding box, and saves the cropped images.\n",
    "def process_images(input_folder, output_folder):\n",
    "    \n",
    "    # Ensure the output folder exists\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # Get all image files in the input folder\n",
    "    image_files = [f for f in os.listdir(input_folder) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "\n",
    "    for filename in image_files:\n",
    "        image_path = os.path.join(input_folder, filename)\n",
    "        image = cv2.imread(image_path)\n",
    "\n",
    "        if image is None:\n",
    "            print(f\"Error: Could not load {image_path}\")\n",
    "            continue\n",
    "\n",
    "        print(f\"Processing {filename}...\")\n",
    "\n",
    "        # Run YOLOv5 for detection\n",
    "        results = model(image)\n",
    "\n",
    "        # Get bounding boxes (xyxy format: [xmin, ymin, xmax, ymax, confidence, class])\n",
    "        detections = results.xyxy[0].cpu().numpy()\n",
    "\n",
    "        # Crop the largest box\n",
    "        cropped_image, best_box = crop_largest_box(image, detections)\n",
    "\n",
    "        if cropped_image is not None:\n",
    "            # Save the cropped image\n",
    "            output_path = os.path.join(output_folder, f\"cropped_{filename}\")\n",
    "            cv2.imwrite(output_path, cropped_image)\n",
    "            print(f\"Saved cropped image to {output_path}\")\n",
    "        else:\n",
    "            print(f\"No valid bounding boxes found for {filename}\")\n",
    "\n",
    "# Define input and output folders\n",
    "input_folder = '/Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/Car Plates'\n",
    "output_folder = '/Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/Cropped Plates'\n",
    "\n",
    "# Process all images\n",
    "process_images(input_folder, output_folder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3682fff4-1f53-448b-ad23-83775997e47f",
   "metadata": {},
   "source": [
    "<b>Step 5: Image Pre-processing<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "22e148ef-8743-4daf-a9ba-cce988716c7f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved preprocessed image to /Users/aysham/Documents/Fall 2024/Computer Vision/Project/P Images/cropped_40.jpeg\n",
      "Saved preprocessed image to /Users/aysham/Documents/Fall 2024/Computer Vision/Project/P Images/cropped_17.jpeg\n",
      "Saved preprocessed image to /Users/aysham/Documents/Fall 2024/Computer Vision/Project/P Images/cropped_21.jpeg\n",
      "Saved preprocessed image to /Users/aysham/Documents/Fall 2024/Computer Vision/Project/P Images/cropped_37.jpeg\n",
      "Saved preprocessed image to /Users/aysham/Documents/Fall 2024/Computer Vision/Project/P Images/cropped_36.jpeg\n",
      "Saved preprocessed image to /Users/aysham/Documents/Fall 2024/Computer Vision/Project/P Images/cropped_20.jpeg\n",
      "Saved preprocessed image to /Users/aysham/Documents/Fall 2024/Computer Vision/Project/P Images/cropped_1.jpeg\n",
      "Saved preprocessed image to /Users/aysham/Documents/Fall 2024/Computer Vision/Project/P Images/cropped_16.jpeg\n",
      "Saved preprocessed image to /Users/aysham/Documents/Fall 2024/Computer Vision/Project/P Images/cropped_41.jpeg\n",
      "Saved preprocessed image to /Users/aysham/Documents/Fall 2024/Computer Vision/Project/P Images/cropped_6.jpeg\n",
      "Saved preprocessed image to /Users/aysham/Documents/Fall 2024/Computer Vision/Project/P Images/cropped_27.jpeg\n",
      "Saved preprocessed image to /Users/aysham/Documents/Fall 2024/Computer Vision/Project/P Images/cropped_31.jpeg\n",
      "Saved preprocessed image to /Users/aysham/Documents/Fall 2024/Computer Vision/Project/P Images/cropped_11.jpeg\n",
      "Saved preprocessed image to /Users/aysham/Documents/Fall 2024/Computer Vision/Project/P Images/cropped_10.jpeg\n",
      "Saved preprocessed image to /Users/aysham/Documents/Fall 2024/Computer Vision/Project/P Images/cropped_30.jpeg\n",
      "Saved preprocessed image to /Users/aysham/Documents/Fall 2024/Computer Vision/Project/P Images/cropped_26.jpeg\n",
      "Saved preprocessed image to /Users/aysham/Documents/Fall 2024/Computer Vision/Project/P Images/cropped_7.jpeg\n",
      "Saved preprocessed image to /Users/aysham/Documents/Fall 2024/Computer Vision/Project/P Images/cropped_33.jpeg\n",
      "Saved preprocessed image to /Users/aysham/Documents/Fall 2024/Computer Vision/Project/P Images/cropped_25.jpeg\n",
      "Saved preprocessed image to /Users/aysham/Documents/Fall 2024/Computer Vision/Project/P Images/cropped_4.jpeg\n",
      "Saved preprocessed image to /Users/aysham/Documents/Fall 2024/Computer Vision/Project/P Images/cropped_29.jpeg\n",
      "Saved preprocessed image to /Users/aysham/Documents/Fall 2024/Computer Vision/Project/P Images/cropped_13.jpeg\n",
      "Saved preprocessed image to /Users/aysham/Documents/Fall 2024/Computer Vision/Project/P Images/cropped_8.jpeg\n",
      "Saved preprocessed image to /Users/aysham/Documents/Fall 2024/Computer Vision/Project/P Images/cropped_9.jpeg\n",
      "Saved preprocessed image to /Users/aysham/Documents/Fall 2024/Computer Vision/Project/P Images/cropped_12.jpeg\n",
      "Saved preprocessed image to /Users/aysham/Documents/Fall 2024/Computer Vision/Project/P Images/cropped_28.jpeg\n",
      "Saved preprocessed image to /Users/aysham/Documents/Fall 2024/Computer Vision/Project/P Images/cropped_5.jpeg\n",
      "Saved preprocessed image to /Users/aysham/Documents/Fall 2024/Computer Vision/Project/P Images/cropped_24.jpeg\n",
      "Saved preprocessed image to /Users/aysham/Documents/Fall 2024/Computer Vision/Project/P Images/cropped_32.jpeg\n",
      "Saved preprocessed image to /Users/aysham/Documents/Fall 2024/Computer Vision/Project/P Images/cropped_39.jpeg\n",
      "Saved preprocessed image to /Users/aysham/Documents/Fall 2024/Computer Vision/Project/P Images/cropped_15.jpeg\n",
      "Saved preprocessed image to /Users/aysham/Documents/Fall 2024/Computer Vision/Project/P Images/cropped_42.jpeg\n",
      "Saved preprocessed image to /Users/aysham/Documents/Fall 2024/Computer Vision/Project/P Images/cropped_35.jpeg\n",
      "Saved preprocessed image to /Users/aysham/Documents/Fall 2024/Computer Vision/Project/P Images/cropped_43.jpg\n",
      "Saved preprocessed image to /Users/aysham/Documents/Fall 2024/Computer Vision/Project/P Images/cropped_23.jpeg\n",
      "Saved preprocessed image to /Users/aysham/Documents/Fall 2024/Computer Vision/Project/P Images/cropped_19.jpeg\n",
      "Saved preprocessed image to /Users/aysham/Documents/Fall 2024/Computer Vision/Project/P Images/cropped_2.jpeg\n",
      "Saved preprocessed image to /Users/aysham/Documents/Fall 2024/Computer Vision/Project/P Images/cropped_3.jpeg\n",
      "Saved preprocessed image to /Users/aysham/Documents/Fall 2024/Computer Vision/Project/P Images/cropped_18.jpeg\n",
      "Saved preprocessed image to /Users/aysham/Documents/Fall 2024/Computer Vision/Project/P Images/cropped_22.jpeg\n",
      "Saved preprocessed image to /Users/aysham/Documents/Fall 2024/Computer Vision/Project/P Images/cropped_34.jpeg\n",
      "Saved preprocessed image to /Users/aysham/Documents/Fall 2024/Computer Vision/Project/P Images/cropped_14.jpeg\n",
      "Saved preprocessed image to /Users/aysham/Documents/Fall 2024/Computer Vision/Project/P Images/cropped_38.jpeg\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Define the paths\n",
    "input_folder = Path('/Users/raisa_hasan/Desktop/Computer Vision/Project/Cropped Plates')\n",
    "output_folder = Path('/Users/raisa_hasan/Desktop/Computer Vision/Project/P Images')\n",
    "output_folder.mkdir(exist_ok=True)  # Create output folder if it doesn't exist\n",
    "\n",
    "# Prepares the image by applying Gaussian blur, CLAHE, and sharpening for OCR readability.\n",
    "def preprocess_image_for_ocr(image):\n",
    "\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply Gaussian Blur to reduce noise slightly\n",
    "    blurred = cv2.GaussianBlur(gray, (3, 3), 0)\n",
    "\n",
    "    # Enhance contrast using CLAHE\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    contrast_enhanced = clahe.apply(blurred)\n",
    "\n",
    "    return contrast_enhanced\n",
    "\n",
    "# Preprocesses images in the input folder and saves the enhanced images to the output folder.\n",
    "def preprocess_and_save_images(input_folder, output_folder):\n",
    "    \n",
    "    for filename in os.listdir(input_folder):\n",
    "        if filename.lower().endswith((\".jpg\", \".jpeg\", \".png\")):\n",
    "            image_path = input_folder / filename\n",
    "            image = cv2.imread(str(image_path))\n",
    "            \n",
    "            if image is not None:\n",
    "                processed_image = preprocess_image_for_ocr(image)\n",
    "                \n",
    "                # Save processed image to output folder\n",
    "                output_path = output_folder / filename\n",
    "                cv2.imwrite(str(output_path), processed_image)\n",
    "                print(f\"Saved preprocessed image to {output_path}\")\n",
    "            else:\n",
    "                print(f\"Error loading image: {image_path}\")\n",
    "\n",
    "# Run preprocessing and save images\n",
    "preprocess_and_save_images(input_folder, output_folder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57acf02-8d5e-41a5-a692-e7af665c54b3",
   "metadata": {},
   "source": [
    "<b>Step 6: EasyOCR to Detect Text on License Plates<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ebb50a-1ac7-442a-bc4d-9a24d61b1927",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image: cropped_1.jpeg - Detected Plate Number (Raw): 934457\n",
      "Image: cropped_2.jpeg - Detected Plate Number (Raw): 802694\n",
      "Image: cropped_3.jpeg - No valid plate text detected after all attempts.\n",
      "Image: cropped_4.jpeg - Detected Plate Number (Raw): 469534\n",
      "Image: cropped_5.jpeg - Detected Plate Number (Preprocessed): 468442\n",
      "Image: cropped_6.jpeg - Detected Plate Number (Preprocessed): 454950\n",
      "Image: cropped_7.jpeg - Detected Plate Number (Raw): 922733\n",
      "Image: cropped_8.jpeg - Detected Plate Number (Raw): 127928\n",
      "Image: cropped_9.jpeg - Detected Plate Number (Raw): 597141\n",
      "Image: cropped_10.jpeg - Detected Plate Number (Raw): 19884\n",
      "Image: cropped_11.jpeg - Detected Plate Number (Raw): 790493\n",
      "Image: cropped_12.jpeg - Detected Plate Number (Raw): 14475\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import easyocr\n",
    "import re\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "# Initialize EasyOCR reader\n",
    "reader = easyocr.Reader(['en'], gpu=False)\n",
    "\n",
    "# Paths\n",
    "project_dir = Path(\"/Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project\")\n",
    "raw_input_folder = project_dir / \"Cropped Plates\"  # Folder with raw images\n",
    "preprocessed_folder = project_dir / \"P Images\"  # Folder with preprocessed images\n",
    "output_folder = project_dir / \"Processed Plates\"  # Folder for successful OCR outputs\n",
    "error_folder = project_dir / \"Error Images\"  # Folder for error images\n",
    "log_file_path = project_dir / \"EasyOcr.txt\"  # File to log results\n",
    "\n",
    "# Ensure output directories exist\n",
    "preprocessed_folder.mkdir(exist_ok=True)\n",
    "output_folder.mkdir(exist_ok=True)\n",
    "error_folder.mkdir(exist_ok=True)\n",
    "\n",
    "# Clear the EasyOcr.txt file if it exists\n",
    "open(log_file_path, \"w\").close()\n",
    "\n",
    "# Function to check if detected text is a valid plate format\n",
    "def is_valid_plate(plate_text):\n",
    "    return bool(re.fullmatch(r'\\d{4,6}', plate_text))\n",
    "\n",
    "# Function to apply sharpening to the image\n",
    "def sharpen_image(image, strength):\n",
    "    blurred = cv2.GaussianBlur(image, (3, 3), 0)\n",
    "    return cv2.addWeighted(image, 1 + strength, blurred, -strength, 0)\n",
    "\n",
    "# Function to run OCR on an image and return the first valid plate number\n",
    "def run_ocr(image):\n",
    "    ocr_results = reader.readtext(image, detail=0)\n",
    "    valid_texts = [text for text in ocr_results if is_valid_plate(text)]\n",
    "    return valid_texts[0] if valid_texts else None\n",
    "\n",
    "# Function to apply EasyOCR and log results in order\n",
    "def apply_easyocr_with_preprocessing(raw_folder, preprocessed_folder, output_folder, error_folder, log_file_path, resize_factor=0.5, sharpness_strength=1.5):\n",
    "    # List and sort image files by numeric order\n",
    "    raw_image_files = sorted(\n",
    "        [f for f in os.listdir(raw_folder) if re.search(r'\\d+', f)],\n",
    "        key=lambda x: int(re.search(r'\\d+', x).group())\n",
    "    )\n",
    "\n",
    "    # Dictionary to hold the final results for each image\n",
    "    final_results = {}\n",
    "\n",
    "    for filename in raw_image_files:\n",
    "        raw_image_path = raw_folder / filename\n",
    "        preprocessed_image_path = preprocessed_folder / filename\n",
    "        image = cv2.imread(str(raw_image_path))\n",
    "\n",
    "        if image is None:\n",
    "            final_results[filename] = \"NaN\"\n",
    "            error_path = error_folder / f\"error_{filename}\"\n",
    "            cv2.imwrite(str(error_path), np.zeros((100, 100, 3), dtype=np.uint8))  # Save blank image if loading fails\n",
    "            print(f\"Error loading image: {raw_image_path}\")\n",
    "            continue\n",
    "\n",
    "        # Attempt OCR on raw image\n",
    "        detected_text = run_ocr(image)\n",
    "        if detected_text:\n",
    "            final_results[filename] = detected_text\n",
    "            output_path = output_folder / f\"ocr_{filename}\"\n",
    "            cv2.imwrite(str(output_path), image)\n",
    "            print(f\"Image: {filename} - Detected Plate Number (Raw): {detected_text}\")\n",
    "            continue\n",
    "\n",
    "        # Apply preprocessing and retry OCR\n",
    "        gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        resized_image = cv2.resize(gray_image, None, fx=resize_factor, fy=resize_factor)\n",
    "        detected_text = run_ocr(resized_image)\n",
    "        if detected_text:\n",
    "            final_results[filename] = detected_text\n",
    "            output_path = output_folder / f\"ocr_{filename}\"\n",
    "            cv2.imwrite(str(output_path), resized_image)\n",
    "            print(f\"Image: {filename} - Detected Plate Number (Preprocessed): {detected_text}\")\n",
    "            continue\n",
    "\n",
    "        # Apply sharpening and retry OCR\n",
    "        sharpened_image = sharpen_image(resized_image, sharpness_strength)\n",
    "        detected_text = run_ocr(sharpened_image)\n",
    "        if detected_text:\n",
    "            final_results[filename] = detected_text\n",
    "            output_path = output_folder / f\"ocr_{filename}\"\n",
    "            cv2.imwrite(str(output_path), sharpened_image)\n",
    "            print(f\"Image: {filename} - Detected Plate Number after sharpening: {detected_text}\")\n",
    "        else:\n",
    "            final_results[filename] = \"NaN\"\n",
    "            error_path = error_folder / f\"error_{filename}\"\n",
    "            cv2.imwrite(str(error_path), image)\n",
    "            print(f\"Image: {filename} - No valid plate text detected after all attempts.\")\n",
    "\n",
    "    # Write the final results to the log file\n",
    "    with open(log_file_path, \"w\") as log_file:\n",
    "        # Sort by numeric order of filenames\n",
    "        for filename, plate_number in sorted(final_results.items(), key=lambda x: int(re.search(r'\\d+', x[0]).group())):\n",
    "            log_file.write(f\"Image: {filename} Licence plate Number: {plate_number}\\n\")\n",
    "\n",
    "# Run the OCR process\n",
    "apply_easyocr_with_preprocessing(raw_input_folder, preprocessed_folder, output_folder, error_folder, log_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ca01f3-ef43-4f86-8565-25dca1194af3",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "<b>Step 7: Create carplates.txt<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50fbe34-6627-43b2-9d96-401e863bc776",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the carplates.txt file\n",
    "carplates_content = \"\"\"\n",
    "Image: 1 Licence plate Number: 934457\n",
    "Image: 2 Licence plate Number: 802694\n",
    "Image: 3 Licence plate Number: 485120\n",
    "Image: 4 Licence plate Number: 469534\n",
    "Image: 5 Licence plate Number: 468442\n",
    "Image: 6 Licence plate Number: 454950\n",
    "Image: 7 Licence plate Number: 922733\n",
    "Image: 8 Licence plate Number: 127928\n",
    "Image: 9 Licence plate Number: 597141\n",
    "Image: 10 Licence plate Number: 19884\n",
    "Image: 11 Licence plate Number: 790493\n",
    "Image: 12 Licence plate Number: 14475\n",
    "Image: 13 Licence plate Number: 498494\n",
    "Image: 14 Licence plate Number: 294510\n",
    "Image: 15 Licence plate Number: 75339\n",
    "Image: 16 Licence plate Number: 546901\n",
    "Image: 17 Licence plate Number: 279995\n",
    "Image: 18 Licence plate Number: 626821\n",
    "Image: 19 Licence plate Number: 843957\n",
    "Image: 20 Licence plate Number: 419292\n",
    "Image: 21 Licence plate Number: 534009\n",
    "Image: 22 Licence plate Number: 534009\n",
    "Image: 23 Licence plate Number: 574358\n",
    "Image: 24 Licence plate Number: 37374\n",
    "Image: 25 Licence plate Number: 341688\n",
    "Image: 26 Licence plate Number: 754337\n",
    "Image: 27 Licence plate Number: 644531\n",
    "Image: 28 Licence plate Number: 667934\n",
    "Image: 29 Licence plate Number: 823998\n",
    "Image: 30 Licence plate Number: 108902\n",
    "Image: 31 Licence plate Number: 532670\n",
    "Image: 32 Licence plate Number: 751616\n",
    "Image: 33 Licence plate Number: 585388\n",
    "Image: 34 Licence plate Number: 224585\n",
    "Image: 35 Licence plate Number: 809986\n",
    "Image: 36 Licence plate Number: 674202\n",
    "Image: 37 Licence plate Number: 362231\n",
    "Image: 38 Licence plate Number: 50885\n",
    "Image: 39 Licence plate Number: 401048\n",
    "Image: 40 Licence plate Number: 67400\n",
    "Image: 41 Licence plate Number: 498839\n",
    "Image: 42 Licence plate Number: 644710\n",
    "Image: 43 Licence plate Number: 4323\n",
    "\"\"\"\n",
    "\n",
    "file_path = \"/Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/carplates.txt\"\n",
    "\n",
    "# Write content to file\n",
    "with open(file_path, \"w\") as file:\n",
    "    file.write(carplates_content)\n",
    "\n",
    "file_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab0ae78-c0f3-458e-8ed1-e94cb0ca3273",
   "metadata": {},
   "source": [
    "<b>Step 8: Supervised Learning<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9c098190-46ef-4b60-9e6c-3abdba6ca3fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mImage cropped_1.jpeg: Success! EasyOCR result matches the ground truth: 934457\u001b[0m\n",
      "\u001b[92mImage cropped_2.jpeg: Success! EasyOCR result matches the ground truth: 802694\u001b[0m\n",
      "\u001b[92mImage cropped_3.jpeg: Success! EasyOCR result matches the ground truth: 485120\u001b[0m\n",
      "\u001b[92mImage cropped_4.jpeg: Success! EasyOCR result matches the ground truth: 469534\u001b[0m\n",
      "\u001b[92mImage cropped_5.jpeg: Success! EasyOCR result matches the ground truth: 468442\u001b[0m\n",
      "\u001b[92mImage cropped_6.jpeg: Success! EasyOCR result matches the ground truth: 454950\u001b[0m\n",
      "\u001b[92mImage cropped_7.jpeg: Success! EasyOCR result matches the ground truth: 922733\u001b[0m\n",
      "\u001b[92mImage cropped_8.jpeg: Success! EasyOCR result matches the ground truth: 127928\u001b[0m\n",
      "\u001b[92mImage cropped_9.jpeg: Success! EasyOCR result matches the ground truth: 597141\u001b[0m\n",
      "\u001b[92mImage cropped_10.jpeg: Success! EasyOCR result matches the ground truth: 19884\u001b[0m\n",
      "\u001b[92mImage cropped_11.jpeg: Success! EasyOCR result matches the ground truth: 790493\u001b[0m\n",
      "\u001b[92mImage cropped_12.jpeg: Success! EasyOCR result matches the ground truth: 14475\u001b[0m\n",
      "\u001b[92mImage cropped_13.jpeg: Success! EasyOCR result matches the ground truth: 498494\u001b[0m\n",
      "\u001b[92mImage cropped_14.jpeg: Success! EasyOCR result matches the ground truth: 294510\u001b[0m\n",
      "\u001b[92mImage cropped_15.jpeg: Success! EasyOCR result matches the ground truth: 75339\u001b[0m\n",
      "\u001b[92mImage cropped_16.jpeg: Success! EasyOCR result matches the ground truth: 546901\u001b[0m\n",
      "\u001b[92mImage cropped_17.jpeg: Success! EasyOCR result matches the ground truth: 279995\u001b[0m\n",
      "\u001b[92mImage cropped_18.jpeg: Success! EasyOCR result matches the ground truth: 626821\u001b[0m\n",
      "\u001b[92mImage cropped_19.jpeg: Success! EasyOCR result matches the ground truth: 843957\u001b[0m\n",
      "\u001b[91mImage cropped_20.jpeg: Failed! Incorrect plate number. Detected: 6401, Correct: 419292\u001b[0m\n",
      "\u001b[92mImage cropped_21.jpeg: Success! EasyOCR result matches the ground truth: 534009\u001b[0m\n",
      "\u001b[92mImage cropped_22.jpeg: Success! EasyOCR result matches the ground truth: 534009\u001b[0m\n",
      "\u001b[92mImage cropped_23.jpeg: Success! EasyOCR result matches the ground truth: 574358\u001b[0m\n",
      "\u001b[92mImage cropped_24.jpeg: Success! EasyOCR result matches the ground truth: 37374\u001b[0m\n",
      "\u001b[91mImage cropped_25.jpeg: Error! The plate number wasn't detected; the correct plate number is: 341688\u001b[0m\n",
      "\u001b[92mImage cropped_26.jpeg: Success! EasyOCR result matches the ground truth: 754337\u001b[0m\n",
      "\u001b[92mImage cropped_27.jpeg: Success! EasyOCR result matches the ground truth: 644531\u001b[0m\n",
      "\u001b[92mImage cropped_28.jpeg: Success! EasyOCR result matches the ground truth: 667934\u001b[0m\n",
      "\u001b[92mImage cropped_29.jpeg: Success! EasyOCR result matches the ground truth: 823998\u001b[0m\n",
      "\u001b[92mImage cropped_30.jpeg: Success! EasyOCR result matches the ground truth: 108902\u001b[0m\n",
      "\u001b[92mImage cropped_31.jpeg: Success! EasyOCR result matches the ground truth: 532670\u001b[0m\n",
      "\u001b[92mImage cropped_32.jpeg: Success! EasyOCR result matches the ground truth: 751616\u001b[0m\n",
      "\u001b[92mImage cropped_33.jpeg: Success! EasyOCR result matches the ground truth: 585388\u001b[0m\n",
      "\u001b[92mImage cropped_34.jpeg: Success! EasyOCR result matches the ground truth: 224585\u001b[0m\n",
      "\u001b[91mImage cropped_35.jpeg: Error! The plate number wasn't detected; the correct plate number is: 809986\u001b[0m\n",
      "\u001b[91mImage cropped_36.jpeg: There is a mistake in digit(s) 3. The correct plate number is: 674202\u001b[0m\n",
      "\u001b[92mImage cropped_37.jpeg: Success! EasyOCR result matches the ground truth: 362231\u001b[0m\n",
      "\u001b[92mImage cropped_38.jpeg: Success! EasyOCR result matches the ground truth: 50885\u001b[0m\n",
      "\u001b[92mImage cropped_39.jpeg: Success! EasyOCR result matches the ground truth: 401048\u001b[0m\n",
      "\u001b[92mImage cropped_40.jpeg: Success! EasyOCR result matches the ground truth: 67400\u001b[0m\n",
      "\u001b[91mImage cropped_41.jpeg: Error! The plate number wasn't detected; the correct plate number is: 498839\u001b[0m\n",
      "\u001b[92mImage cropped_42.jpeg: Success! EasyOCR result matches the ground truth: 644710\u001b[0m\n",
      "\u001b[92mImage cropped_43.jpeg: Success! EasyOCR result matches the ground truth: 4323\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "# Compare EasyOCR results with ground truth and classify results into TP, FP, TN, FN.\n",
    "# Handles duplicate image entries by considering only the last processed entry for each image.\n",
    "def compare_easyocr_with_ground_truth(ocr_results_path, ground_truth_path, calculation_file_path):\n",
    "    try:\n",
    "        # Color codes for colored messages\n",
    "        GREEN = '\\033[92m'\n",
    "        RED = '\\033[91m'\n",
    "        RESET = '\\033[0m'\n",
    "\n",
    "        # Read files\n",
    "        with open(ocr_results_path, 'r') as ocr_file:\n",
    "            ocr_lines = ocr_file.readlines()\n",
    "        with open(ground_truth_path, 'r') as gt_file:\n",
    "            gt_lines = gt_file.readlines()\n",
    "\n",
    "        # Process OCR results, keeping only the last valid entry for each image\n",
    "        ocr_data = {}\n",
    "        for line in ocr_lines:\n",
    "            match = re.search(r'Image: (cropped_\\d+\\.(jpeg|jpg)).*?Licence plate Number: (\\d+|NaN)', line)\n",
    "            if match:\n",
    "                image, _, plate = match.groups()\n",
    "                ocr_data[image] = plate  # Overwrite to keep the last entry\n",
    "\n",
    "        # Process ground truth\n",
    "        gt_data = {}\n",
    "        for line in gt_lines:\n",
    "            match = re.search(r'Image: (\\d+).*?Licence plate Number: (\\d+)', line)\n",
    "            if match:\n",
    "                image, plate = match.groups()\n",
    "                gt_data[f\"cropped_{image}.jpeg\"] = plate\n",
    "\n",
    "        # Consolidate duplicate extensions in OCR data\n",
    "        consolidated_ocr_data = {}\n",
    "        for image, plate in ocr_data.items():\n",
    "            base_name = re.sub(r'\\.\\w+$', '', image)  # Remove file extension\n",
    "            consolidated_ocr_data[base_name] = plate\n",
    "\n",
    "        # Create the calculation file\n",
    "        with open(calculation_file_path, \"w\") as calc_file:\n",
    "            for gt_image, gt_plate in gt_data.items():\n",
    "                base_name = re.sub(r'\\.\\w+$', '', gt_image)\n",
    "                ocr_plate = consolidated_ocr_data.get(base_name, \"NaN\")  # Default to NaN if not found\n",
    "\n",
    "                if ocr_plate == gt_plate:\n",
    "                    label = \"TP\"  # True Positive\n",
    "                    message = f\"Image {gt_image}: Success! EasyOCR result matches the ground truth: {gt_plate}\"\n",
    "                    print(GREEN + message + RESET)\n",
    "                elif ocr_plate == \"NaN\":\n",
    "                    label = \"FN\"  # False Negative\n",
    "                    message = f\"Image {gt_image}: Error! The plate number wasn't detected; the correct plate number is: {gt_plate}\"\n",
    "                    print(RED + message + RESET)\n",
    "                elif len(ocr_plate) == len(gt_plate) and ocr_plate != gt_plate:\n",
    "                    if all(ocr_plate[i] != gt_plate[i] for i in range(len(gt_plate))):\n",
    "                        label = \"FN\"  # Completely incorrect plate\n",
    "                        message = f\"Image {gt_image}: Failed! Completely wrong number. Correct number is: {gt_plate}\"\n",
    "                        print(RED + message + RESET)\n",
    "                    else:\n",
    "                        label = \"FP\"  # Partial mismatch\n",
    "                        mismatched_digits = [\n",
    "                            idx + 1\n",
    "                            for idx, (ocr_digit, gt_digit) in enumerate(zip(ocr_plate, gt_plate))\n",
    "                            if ocr_digit != gt_digit\n",
    "                        ]\n",
    "                        message = (\n",
    "                            f\"Image {gt_image}: There is a mistake in digit(s) {', '.join(map(str, mismatched_digits))}. \"\n",
    "                            f\"The correct plate number is: {gt_plate}\"\n",
    "                        )\n",
    "                        print(RED + message + RESET)\n",
    "                else:\n",
    "                    label = \"FP\"  # Incorrect detection\n",
    "                    message = f\"Image {gt_image}: Failed! Incorrect plate number. Detected: {ocr_plate}, Correct: {gt_plate}\"\n",
    "                    print(RED + message + RESET)\n",
    "\n",
    "                # Write the result to the calculation file\n",
    "                calc_file.write(f\"Image: {gt_image}, Car Plate: {gt_plate}, Detected: {ocr_plate}, Label: {label}\\n\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(RED + f\"An error occurred: {e}\" + RESET)\n",
    "\n",
    "\n",
    "# Paths to the EasyOCR results, ground truth, and calculation file\n",
    "ocr_results_path = \"/Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/EasyOcr.txt\"\n",
    "ground_truth_path = \"/Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/carplates.txt\"\n",
    "calculation_file_path = \"/Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/calculation.txt\"\n",
    "\n",
    "# Run the comparison\n",
    "compare_easyocr_with_ground_truth(ocr_results_path, ground_truth_path, calculation_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae74336-54f1-4291-b3f3-09184150e686",
   "metadata": {},
   "source": [
    "<b>Step 9: Evaluation Matrix<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d55a72fb-7899-4273-b28d-8173827a7f99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "True Positives (TP): 38\n",
      "True Negatives (TN): 0\n",
      "False Positives (FP): 2\n",
      "False Negatives (FN): 3\n",
      "\n",
      "Evaluation Metrics:\n",
      "Accuracy: 0.8837\n",
      "Precision: 0.9500\n",
      "Recall: 0.9268\n",
      "F1-Score: 0.9383\n"
     ]
    }
   ],
   "source": [
    "# Compute TP, TN, FP, FN, accuracy, precision, recall, and F1-score.\n",
    "def evaluate_from_calculations(file_path):\n",
    "    try:\n",
    "        # Initialize counts for confusion matrix\n",
    "        TP, TN, FP, FN = 0, 0, 0, 0\n",
    "\n",
    "        # Read the calculation file\n",
    "        with open(file_path, 'r') as file:\n",
    "            lines = file.readlines()\n",
    "\n",
    "        # Count occurrences of each label\n",
    "        for line in lines:\n",
    "            # True Positive: OCR detected the plate correctly, and it matches the ground truth\n",
    "            if \"Label: TP\" in line:\n",
    "                TP += 1\n",
    "            # True Negative: No plate was present in the image, and OCR correctly identified this\n",
    "            elif \"Label: TN\" in line:\n",
    "                TN += 1\n",
    "            # False Positive: OCR detected an incorrect plate (wrong digits or almost correct)\n",
    "            elif \"Label: FP\" in line:\n",
    "                FP += 1\n",
    "            # False Negative: OCR failed to detect the plate number entirely\n",
    "            elif \"Label: FN\" in line:\n",
    "                FN += 1\n",
    "\n",
    "        # Calculate evaluation metrics\n",
    "        total = TP + TN + FP + FN\n",
    "        accuracy = (TP + TN) / total if total > 0 else 0\n",
    "        precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "        recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "        f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "        # Print the results\n",
    "        print(\"Confusion Matrix:\")\n",
    "        print(f\"True Positives (TP): {TP}\")\n",
    "        print(f\"True Negatives (TN): {TN}\")\n",
    "        print(f\"False Positives (FP): {FP}\")\n",
    "        print(f\"False Negatives (FN): {FN}\")\n",
    "        print(\"\\nEvaluation Metrics:\")\n",
    "        print(f\"Accuracy: {accuracy:.4f}\")\n",
    "        print(f\"Precision: {precision:.4f}\")\n",
    "        print(f\"Recall: {recall:.4f}\")\n",
    "        print(f\"F1-Score: {f1_score:.4f}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "# Path to the calculation file\n",
    "calculation_file_path = \"/Users/raisa_hasan/Desktop/Web/Cpmputer_Vision_project/calculation.txt\"\n",
    "evaluate_from_calculations(calculation_file_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
